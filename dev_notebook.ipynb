{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>หลังจากนี้ไม่จัดเทียร์แล้วนะเป็นร้านที่กินบ่อย...</td>\n",
       "      <td>หลังจากนี้ไม่จัดเทียร์แล้วนะเป็นร้านที่กินบ่อย...</td>\n",
       "      <td>หลังจากนี้ไม่จัดเทียร์แล้วนะเป็นร้านที่กินบ่อย...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2) นายฉั่ว (จอดองค์พระเดินมาตลาดล่าง) เจ้าดังค...</td>\n",
       "      <td>2) นายฉั่ว (จอดองค์พระเดินมาตลาดล่าง) เจ้าดังค...</td>\n",
       "      <td>นายฉั่วจอดองค์พระเดินมาตลาดล่างเจ้าดังคิวยาวไป...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>รีวิวเลยแล้วกัน ขอจัดเทียร์ร้านข้าวหมูแดงที่คน...</td>\n",
       "      <td>รีวิวเลยแล้วกัน ขอจัดเทียร์ร้านข้าวหมูแดงที่คน...</td>\n",
       "      <td>รีวิวเลยแล้วกันขอจัดเทียร์ร้านข้าวหมูแดงที่คนน...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@absoluteJB ข้าวหมูแดงร้านนายฉั่ว ตรงตลาดล่างต...</td>\n",
       "      <td>@ ข้าวหมูแดงร้านนายฉั่ว ตรงตลาดล่างตรงข้ามองค์...</td>\n",
       "      <td>ข้าวหมูแดงร้านนายฉั่วตรงตลาดล่างตรงข้ามองค์พระ...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ตลาดล่างมอจริงๆด้วย</td>\n",
       "      <td>ตลาดล่างมอจริงๆด้วย</td>\n",
       "      <td>ตลาดล่างมอจริงๆด้วย</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  หลังจากนี้ไม่จัดเทียร์แล้วนะเป็นร้านที่กินบ่อย...   \n",
       "1  2) นายฉั่ว (จอดองค์พระเดินมาตลาดล่าง) เจ้าดังค...   \n",
       "2  รีวิวเลยแล้วกัน ขอจัดเทียร์ร้านข้าวหมูแดงที่คน...   \n",
       "3  @absoluteJB ข้าวหมูแดงร้านนายฉั่ว ตรงตลาดล่างต...   \n",
       "4                                ตลาดล่างมอจริงๆด้วย   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  หลังจากนี้ไม่จัดเทียร์แล้วนะเป็นร้านที่กินบ่อย...   \n",
       "1  2) นายฉั่ว (จอดองค์พระเดินมาตลาดล่าง) เจ้าดังค...   \n",
       "2  รีวิวเลยแล้วกัน ขอจัดเทียร์ร้านข้าวหมูแดงที่คน...   \n",
       "3  @ ข้าวหมูแดงร้านนายฉั่ว ตรงตลาดล่างตรงข้ามองค์...   \n",
       "4                                ตลาดล่างมอจริงๆด้วย   \n",
       "\n",
       "                                                Text Class  \n",
       "0  หลังจากนี้ไม่จัดเทียร์แล้วนะเป็นร้านที่กินบ่อย...  none  \n",
       "1  นายฉั่วจอดองค์พระเดินมาตลาดล่างเจ้าดังคิวยาวไป...  none  \n",
       "2  รีวิวเลยแล้วกันขอจัดเทียร์ร้านข้าวหมูแดงที่คนน...  none  \n",
       "3  ข้าวหมูแดงร้านนายฉั่วตรงตลาดล่างตรงข้ามองค์พระ...  none  \n",
       "4                                ตลาดล่างมอจริงๆด้วย  none  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_file = \"data\\ข้อมูลแยกประเภทเอาไปทดลอง .xlsx - Sheet1 (2).csv\"\n",
    "dataset = pd.read_csv(dataset_file)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>tags_num</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>หลังจากนี้ไม่จัดเทียร์แล้วนะเป็นร้านที่กินบ่อย...</td>\n",
       "      <td>หลังจากนี้ไม่จัดเทียร์แล้วนะเป็นร้านที่กินบ่อย...</td>\n",
       "      <td>หลังจากนี้ไม่จัดเทียร์แล้วนะเป็นร้านที่กินบ่อย...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>[หลังจากนี้, เทียร์, ร้าน, กิน, ไว้ใจได้, อาทิ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2) นายฉั่ว (จอดองค์พระเดินมาตลาดล่าง) เจ้าดังค...</td>\n",
       "      <td>2) นายฉั่ว (จอดองค์พระเดินมาตลาดล่าง) เจ้าดังค...</td>\n",
       "      <td>นายฉั่วจอดองค์พระเดินมาตลาดล่างเจ้าดังคิวยาวไป...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>[ฉั่ว, จอด, องค์, พระ, เดิน, ตลาด, ล่าง, เจ้า,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>รีวิวเลยแล้วกัน ขอจัดเทียร์ร้านข้าวหมูแดงที่คน...</td>\n",
       "      <td>รีวิวเลยแล้วกัน ขอจัดเทียร์ร้านข้าวหมูแดงที่คน...</td>\n",
       "      <td>รีวิวเลยแล้วกันขอจัดเทียร์ร้านข้าวหมูแดงที่คนน...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>[รีวิว, เทียร์, ร้าน, ข้าวหมูแดง, คน, นครปฐม, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@absoluteJB ข้าวหมูแดงร้านนายฉั่ว ตรงตลาดล่างต...</td>\n",
       "      <td>@ ข้าวหมูแดงร้านนายฉั่ว ตรงตลาดล่างตรงข้ามองค์...</td>\n",
       "      <td>ข้าวหมูแดงร้านนายฉั่วตรงตลาดล่างตรงข้ามองค์พระ...</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>[ข้าวหมูแดง, ร้าน, ฉั่ว, ตลาด, ล่าง, ตรงข้าม, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ตลาดล่างมอจริงๆด้วย</td>\n",
       "      <td>ตลาดล่างมอจริงๆด้วย</td>\n",
       "      <td>ตลาดล่างมอจริงๆด้วย</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>[ตลาด, ล่าง, มอ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  หลังจากนี้ไม่จัดเทียร์แล้วนะเป็นร้านที่กินบ่อย...   \n",
       "1  2) นายฉั่ว (จอดองค์พระเดินมาตลาดล่าง) เจ้าดังค...   \n",
       "2  รีวิวเลยแล้วกัน ขอจัดเทียร์ร้านข้าวหมูแดงที่คน...   \n",
       "3  @absoluteJB ข้าวหมูแดงร้านนายฉั่ว ตรงตลาดล่างต...   \n",
       "4                                ตลาดล่างมอจริงๆด้วย   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  หลังจากนี้ไม่จัดเทียร์แล้วนะเป็นร้านที่กินบ่อย...   \n",
       "1  2) นายฉั่ว (จอดองค์พระเดินมาตลาดล่าง) เจ้าดังค...   \n",
       "2  รีวิวเลยแล้วกัน ขอจัดเทียร์ร้านข้าวหมูแดงที่คน...   \n",
       "3  @ ข้าวหมูแดงร้านนายฉั่ว ตรงตลาดล่างตรงข้ามองค์...   \n",
       "4                                ตลาดล่างมอจริงๆด้วย   \n",
       "\n",
       "                                                Text Class  tags_num  \\\n",
       "0  หลังจากนี้ไม่จัดเทียร์แล้วนะเป็นร้านที่กินบ่อย...  none         0   \n",
       "1  นายฉั่วจอดองค์พระเดินมาตลาดล่างเจ้าดังคิวยาวไป...  none         0   \n",
       "2  รีวิวเลยแล้วกันขอจัดเทียร์ร้านข้าวหมูแดงที่คนน...  none         0   \n",
       "3  ข้าวหมูแดงร้านนายฉั่วตรงตลาดล่างตรงข้ามองค์พระ...  none         0   \n",
       "4                                ตลาดล่างมอจริงๆด้วย  none         0   \n",
       "\n",
       "                                          text_clean  \n",
       "0  [หลังจากนี้, เทียร์, ร้าน, กิน, ไว้ใจได้, อาทิ...  \n",
       "1  [ฉั่ว, จอด, องค์, พระ, เดิน, ตลาด, ล่าง, เจ้า,...  \n",
       "2  [รีวิว, เทียร์, ร้าน, ข้าวหมูแดง, คน, นครปฐม, ...  \n",
       "3  [ข้าวหมูแดง, ร้าน, ฉั่ว, ตลาด, ล่าง, ตรงข้าม, ...  \n",
       "4                                   [ตลาด, ล่าง, มอ]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.helper.preparing import convert_labeled, remove_punctuation, remove_stopword\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "\n",
    "dataset_clean = dataset.copy()\n",
    "\n",
    "dataset_clean['tags_num'] = dataset_clean.Class.apply(convert_labeled)\n",
    "dataset_clean['text_clean'] = dataset_clean.Text.apply(remove_punctuation)\n",
    "dataset_clean['text_clean'] = dataset_clean['text_clean'].apply(word_tokenize)\n",
    "dataset_clean['text_clean'] = dataset_clean['text_clean'].apply(remove_stopword)\n",
    "# dataset_clean['text_clean'] = [\" \".join(map(str, w)) for w in dataset_clean.text_clean]\n",
    "\n",
    "dataset_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ก</th>\n",
       "      <th>กก</th>\n",
       "      <th>กค</th>\n",
       "      <th>กง</th>\n",
       "      <th>กช</th>\n",
       "      <th>กฎ</th>\n",
       "      <th>กฎหมาย</th>\n",
       "      <th>กฎหมายอาญา</th>\n",
       "      <th>กฏ</th>\n",
       "      <th>กด</th>\n",
       "      <th>...</th>\n",
       "      <th>้</th>\n",
       "      <th>ํา</th>\n",
       "      <th>ําเนิด</th>\n",
       "      <th>๒๕๕๙</th>\n",
       "      <th>๔</th>\n",
       "      <th>๕</th>\n",
       "      <th>๕๕๕๕</th>\n",
       "      <th>๕๕๕๕๕๕๕</th>\n",
       "      <th>๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕</th>\n",
       "      <th>๖๒๑</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6958 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ก   กก   กค   กง   กช   กฎ  กฎหมาย  กฎหมายอาญา   กฏ   กด  ...    ้   ํา  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0     0.0         0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0     0.0         0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0     0.0         0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0     0.0         0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0     0.0         0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "   ําเนิด  ๒๕๕๙    ๔    ๕  ๕๕๕๕  ๕๕๕๕๕๕๕  ๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕  ๖๒๑  \n",
       "0     0.0   0.0  0.0  0.0   0.0      0.0                    0.0  0.0  \n",
       "1     0.0   0.0  0.0  0.0   0.0      0.0                    0.0  0.0  \n",
       "2     0.0   0.0  0.0  0.0   0.0      0.0                    0.0  0.0  \n",
       "3     0.0   0.0  0.0  0.0   0.0      0.0                    0.0  0.0  \n",
       "4     0.0   0.0  0.0  0.0   0.0      0.0                    0.0  0.0  \n",
       "\n",
       "[5 rows x 6958 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from src.helper.analyzer import identity\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', \n",
    "                                   token_pattern=None, \n",
    "                                   preprocessor=identity, \n",
    "                                   tokenizer=identity)\n",
    "\n",
    "tfidf_vector = tfidf_vectorizer.fit_transform(dataset_clean['text_clean'])\n",
    "tfidf_array = np.array(tfidf_vector.todense())\n",
    "df = pd.DataFrame(tfidf_array,columns=tfidf_vectorizer.get_feature_names_out())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['เลิก', 'กลับเป็น', 'งี่เง่า', 'เเฟน', 'น้ำตา', 'คบ', 'ร้องไห้', 'เกินไป', 'ตอนนั้น', 'วง'])\n",
      " list(['ดำ', 'จุด', 'รอย', 'ช้อต', 'ซีล', 'ฝังใจ', 'ฝ้า', 'ชิ้น', 'หัก', 'จาง'])\n",
      " list(['สิวะ', 'สิว', 'ก', 'กก', 'กค', 'กง', 'กช', 'กฎ', 'กฎหมาย', 'กฎหมายอาญา'])\n",
      " list(['ส่งต่อ', 'ส', 'ขมิ้น', 'ค๊าา', 'เณ', 'เเท้', 'โสม', 'กิน', 'อริ', 'เเคร์'])\n",
      " list(['สิว', 'แต้ม', 'ยุบ', 'ก่อ', 'น้องใหม่', 'แบคทีเรีย', 'กำจัด', 'ใช้ได้', 'หลอด', 'คาง'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nrmoi\\AppData\\Local\\Temp\\ipykernel_19612\\1780175130.py:4: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n",
      "  print(df2.iloc[637:642,:].apply(lambda s: s.nlargest(10).index.tolist(), axis=1).ravel())\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test to display the word from vectorizer\n",
    "\"\"\"\n",
    "tfidf_vector2 = tfidf_vectorizer.fit_transform(dataset_clean['text_clean'])\n",
    "tfidf_array2 = np.array(tfidf_vector2.todense())\n",
    "df2 = pd.DataFrame(tfidf_array2,columns=tfidf_vectorizer.get_feature_names_out())\n",
    "print(df2.iloc[637:642,:].apply(lambda s: s.nlargest(10).index.tolist(), axis=1).ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df\n",
    "y = dataset_clean[('tags_num')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X -------- \n",
      "     ก   กก   กค   กง   กช   กฎ  กฎหมาย  กฎหมายอาญา   กฏ   กด  ...    ้   ํา  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0     0.0         0.0  0.0  0.0  ...  0.0  0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0     0.0         0.0  0.0  0.0  ...  0.0  0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0     0.0         0.0  0.0  0.0  ...  0.0  0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0     0.0         0.0  0.0  0.0  ...  0.0  0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0     0.0         0.0  0.0  0.0  ...  0.0  0.0   \n",
      "\n",
      "   ําเนิด  ๒๕๕๙    ๔    ๕  ๕๕๕๕  ๕๕๕๕๕๕๕  ๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕๕  ๖๒๑  \n",
      "0     0.0   0.0  0.0  0.0   0.0      0.0                    0.0  0.0  \n",
      "1     0.0   0.0  0.0  0.0   0.0      0.0                    0.0  0.0  \n",
      "2     0.0   0.0  0.0  0.0   0.0      0.0                    0.0  0.0  \n",
      "3     0.0   0.0  0.0  0.0   0.0      0.0                    0.0  0.0  \n",
      "4     0.0   0.0  0.0  0.0   0.0      0.0                    0.0  0.0  \n",
      "\n",
      "[5 rows x 6958 columns]\n",
      "Y ------- \n",
      "\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: tags_num, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"X -------- \")\n",
    "print(x.head())\n",
    "print(\"Y ------- \\n\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    " Build the SVM model\n",
    "\"\"\"\n",
    "\n",
    "from sklearn import svm\n",
    "clf_svm = svm.SVC()\n",
    "clf_svm.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_svm.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.60      0.72       237\n",
      "           1       0.80      0.96      0.87       387\n",
      "\n",
      "    accuracy                           0.82       624\n",
      "   macro avg       0.85      0.78      0.80       624\n",
      "weighted avg       0.84      0.82      0.81       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Estimate the SVM model\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logistic = LogisticRegression(random_state=0).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predlogis = model_logistic.predict(x_test)\n",
    "y_predlogis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.56      0.69       237\n",
      "           1       0.78      0.96      0.86       387\n",
      "\n",
      "    accuracy                           0.81       624\n",
      "   macro avg       0.84      0.76      0.78       624\n",
      "weighted avg       0.83      0.81      0.80       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predlogis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export All File here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n The os.path.join used to set paths to export to directories\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    " The os.path.join used to set paths to export to directories\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\nrmoi\\\\Downloads\\\\CyberThesis\\\\vectorizer/verctorizer.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " Export tfidf vectorizer\n",
    "\"\"\"\n",
    "\n",
    "joblib.dump(tfidf_vectorizer, os.path.join(os.getcwd(), \"vectorizer/verctorizer.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\nrmoi\\\\Downloads\\\\CyberThesis\\\\model/svm.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Export SVM Model\n",
    "\"\"\"\n",
    "\n",
    "joblib.dump(clf_svm, os.path.join(os.getcwd(), \"model/svm.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\nrmoi\\\\Downloads\\\\CyberThesis\\\\model/logis.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Export Logis Model\n",
    "\"\"\"\n",
    "\n",
    "joblib.dump(model_logistic, os.path.join(os.getcwd(), \"model/logis.pkl\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
